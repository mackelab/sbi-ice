{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Plot\n",
    "\n",
    "This notebook takes in the trained posteriors and generates various plots used in the paper, namely for the results section. \n",
    "We produce the posterior plot (with predictives) for one layer.\n",
    "Additionally we produce the posterior comparison plot between different layers (and validation data, when available).\n",
    "\n",
    "We also evaluated the expected MSE of the posterior predictive relative to the ground truths in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from omegaconf import DictConfig,OmegaConf\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from sbi_ice.loaders import ShortProfileLoader\n",
    "import sbi.analysis as analysis\n",
    "from sbi_ice.utils import posterior_utils,modelling_utils,plotting_utils,misc\n",
    "import matplotlib.pyplot as plt\n",
    "from tueplots import figsizes\n",
    "\n",
    "data_dir,output_dir = misc.get_data_output_dirs()\n",
    "work_folder = misc.get_project_root()\n",
    "color_opts = plotting_utils.setup_plots()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Posterior Config for posterior we want to work with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeds = [layer_0_seed_101,layer_1_seed_100,layer_2_seed_101,layer_3_seed_103] #Ekstrom exp 2 all_final seeds\n",
    "#seeds = [layer_0_seed_1100,layer_1_seed_1102,layer_2_seed_1104,layer_3_seed_1101] #Synthetic_long exp3 all_final seeds\n",
    "#seeds = [layer_0_seed_1200,layer_1_seed_1203] #Synthetic exp3 all_final_v3 seeds\n",
    "# shelf = \"Synthetic_long\"\n",
    "# exp = \"exp3\"\n",
    "# name = \"all_final\"\n",
    "# seed = \"layer_3_seed_1101\"\n",
    "# name = \"all_final_v3\"\n",
    "# seed = \"layer_1_seed_1203\"\n",
    "shelf = \"Ekstrom\"\n",
    "exp = \"exp2\"\n",
    "name = \"all_final\"\n",
    "seed = \"layer_0_seed_101\"\n",
    "fol = Path(output_dir , shelf, exp, \"sbi_sims/post_predictives\" , name,seed)\n",
    "cfg_path = Path(fol,\"config.yaml\")\n",
    "cfg = OmegaConf.load(cfg_path)\n",
    "config_fol = cfg.posterior_config_fol\n",
    "config_fol = Path(output_dir,shelf,exp,\"sbi_sims/posteriors\",name)\n",
    "print(\"Path to config file: \" , Path(config_fol,str(cfg.name),\"config.yaml\"))\n",
    "\n",
    "\n",
    "n_post_samples = cfg.n_post_samples\n",
    "n_predictive_sims = cfg.n_predictive_sims\n",
    "print(\"number of predictive sims loaded: \" , n_predictive_sims)\n",
    "overwrite = cfg.overwrite_saved_sims\n",
    "posterior_config = OmegaConf.load(Path(config_fol,str(cfg.name),\"config.yaml\"))\n",
    "print(\"Path to posterior config file: \" ,posterior_config)\n",
    "\n",
    "\n",
    "paths = posterior_config.paths\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "output_fol = os.getcwd()\n",
    "print(\"Path to output folder where sims are stored: \", output_fol)\n",
    "\n",
    "shelf_setup_path = paths.shelf_setup_path\n",
    "print(\"Setup file for shelf: \", shelf_setup_path)\n",
    "\n",
    "\n",
    "shelf_folder_path = paths.shelf_folder_path\n",
    "exp_path = paths.exp_path\n",
    "\n",
    "print(\"Read Config files\")\n",
    "loader = ShortProfileLoader.ShortProfileLoader(Path(work_folder,shelf_setup_path),Path(work_folder,shelf_folder_path),exp_path,sims_path=\"layer_sims\",gt_version = posterior_config.gt_version)\n",
    "loader._jobs = [i for i in range(1,200)]\n",
    "loader._num_sims = [1000 for i in range(1,200)]\n",
    "loader.total_sims = 1000*200\n",
    "print(\"Set up data loader\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load posterior network, true values, and posterior predictive simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(config_fol,str(cfg.name),\"inference.p\"), \"rb\") as f:\n",
    "    if device.type == \"cpu\":\n",
    "        out = posterior_utils.CPU_Unpickler(f).load()\n",
    "    else:\n",
    "        out = pickle.load(f)\n",
    "\n",
    "\n",
    "inference = out[\"inference\"]\n",
    "prior = out[\"prior\"]\n",
    "layer_mask = out[\"layer_mask\"]\n",
    "smb_mask = out[\"smb_mask\"]\n",
    "true_layer = torch.tensor(loader.real_layers[cfg.layer_idx][layer_mask]).float()\n",
    "posterior = inference.build_posterior(inference._neural_net.to(\"cpu\"))\n",
    "posterior.set_default_x(true_layer)\n",
    "samples = posterior.sample((n_post_samples,))\n",
    "try:\n",
    "    true_smb = loader._true_smb_const_mean + loader._true_smb_var*loader._true_smb_unperturbed\n",
    "    #true_smb = true_smb[smb_mask]\n",
    "    true_smb = modelling_utils.regrid(loader._true_xmb,true_smb,loader.x)\n",
    "except:\n",
    "    true_smb=None\n",
    "spatial_samples = samples\n",
    "print(spatial_samples.shape)\n",
    "\n",
    "print(\"Reading posterior predictive sims from file...\")\n",
    "with open(Path(fol,\"post_predictive.p\"), \"rb\") as f:\n",
    "    out = pickle.load(f)\n",
    "    bmb_samples = out[\"bmb_samples\"]\n",
    "    best_layers = out[\"best_layers\"]\n",
    "    norms = out[\"norms\"]\n",
    "    ages = out[\"ages\"]\n",
    "    active_trackers = out[\"active_trackers\"]\n",
    "\n",
    "print(\"Finished posterior predictive sims\")\n",
    "print(best_layers.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.mean(true_layer))\n",
    "print(np.mean(loader.surface-loader.real_layers[cfg.layer_idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prior simulations for comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_arrays,norm_arrays,age_arrays,smb_unperturbed_all,smb_cnst_means_all,smb_sds_all,smb_all,bmb_all = \\\n",
    "    loader.load_training_data(layers_fname = posterior_config.layers_fname,mb_fname = posterior_config.mb_fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Main Results plot for this shelf/experiment/IRH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ages = [49.5,  99.5,  149.5, 299.5] #Synthetic_long exp3\n",
    "# true_age = true_ages[cfg.layer_idx]\n",
    "true_age = None\n",
    "layer_idx = cfg.layer_idx\n",
    "\n",
    "plot_layer_mask = layer_mask\n",
    "#plot_layer_mask = np.ones_like(layer_mask).astype(bool)\n",
    "perm = torch.randperm(smb_all.size(0))\n",
    "perm_idx = perm[:1000]\n",
    "prior_samples = smb_all[perm_idx][:,smb_mask]\n",
    "prior_spatial_samples = prior_samples\n",
    "tmb = smb_all[0].numpy() + bmb_all[0].numpy()\n",
    "title = shelf + \" Layer {} Posterior Predictive\".format(layer_idx+1)\n",
    "print(contour_arrays[cfg.layer_idx,:n_predictive_sims,:].shape)\n",
    "fig,axs = plotting_utils.plot_posterior_nice(x = loader.x,\n",
    "                                            mb_mask = smb_mask,\n",
    "                                            tmb = tmb,\n",
    "                                            prior_smb_samples = prior_spatial_samples,\n",
    "                                            posterior_smb_samples = spatial_samples,\n",
    "                                            layer_mask = plot_layer_mask,\n",
    "                                            LMI_boundary = loader.x[layer_mask][0],\n",
    "                                            prior_layer_samples= contour_arrays[cfg.layer_idx,perm_idx,:],\n",
    "                                            prior_layer_ages=age_arrays[cfg.layer_idx,perm_idx],\n",
    "                                            posterior_layer_samples=best_layers,\n",
    "                                            posterior_layer_ages=ages,\n",
    "                                            true_layer=loader._real_layers[cfg.layer_idx],\n",
    "                                            shelf_base=loader.base.flatten(),\n",
    "                                            shelf_surface=loader.surface.flatten(),\n",
    "                                            true_smb=true_smb,\n",
    "                                            true_age=true_age,\n",
    "                                            plot_samples=False,\n",
    "                                            title=title,\n",
    "                                            )\n",
    "fig_name = Path(output_dir,\"paper_figures\",shelf,name + \"_\" + seed + \"_\" + \"predictive.pdf\")\n",
    "fig_name.parent.mkdir(parents=True,exist_ok=True)\n",
    "fig.savefig(fig_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(ages,16))\n",
    "print(np.percentile(ages,50))\n",
    "print(np.percentile(ages,84))\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmb_samples = spatial_samples - torch.Tensor(tmb[smb_mask]).unsqueeze(0)\n",
    "print(bmb_samples.mean(0))\n",
    "print(bmb_samples.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Pairplot of SMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = [[-1.0,2.0] for i in range(0,spatial_samples.shape[1])]\n",
    "subset = [5*i for i in range(10)]\n",
    "labels = [\"{:.2f} km\".format(1.25*np.round(loader.x[10*i]/1250,0)) for i in range(0,spatial_samples.shape[1])]\n",
    "\n",
    "# fig,axs = analysis.pairplot([spatial_samples,prior_spatial_samples],subset=subset,limits=limits,labels=labels,\n",
    "#                             samples_colors=[color_opts[\"colors\"][\"posterior\"],color_opts[\"colors\"][\"prior\"]],\n",
    "#                             upper=\"contour\",contour_offdiag={\"levels\": [0.68,0.95], \"percentile\": True},\n",
    "#                             points_offdiag={\"marker\": \".\",\"markersize\": 5,},points_colors=color_opts[\"colors\"][\"observation\"])\n",
    "\n",
    "# fig_name = Path(output_dir,\"paper_figures\",shelf,name + \"_\" + seed + \"_\" + \"pairplot.pdf\")\n",
    "# fig_name.parent.mkdir(parents=True,exist_ok=True)\n",
    "# fig.savefig(fig_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Yearly Samples of Kottas Traverse Accumulation Data alongside SMB posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kottas_fname =  Path(data_dir,\"Ekstrom\",\"kottas_mbs.p\")\n",
    "with open(kottas_fname, \"rb\") as f:\n",
    "    kottas_smb = pickle.load(f)\n",
    "plt.rcParams.update(figsizes.icml2022_full(height_to_width_ratio=1/1.1))\n",
    "fig, ax = plt.subplots()\n",
    "color_opts = plotting_utils.color_opts\n",
    "\n",
    "ax.hlines(0,loader.x[smb_mask][0]/1e3,loader.x[smb_mask][-1]/1e3,color=\"black\",linestyle=\"--\")\n",
    "kt1, = ax.plot(kottas_smb[\"kottas_xmb\"]/1e3,kottas_smb[\"kottas_time_mean_smb\"],color=color_opts[\"colors\"][\"observation\"])\n",
    "for i,signal in enumerate(kottas_smb[\"all_years_smb\"]):\n",
    "    if i ==0:\n",
    "        label = \"Kottas years\"\n",
    "    else:\n",
    "        label = None\n",
    "    kts, = ax.plot(kottas_smb[\"kottas_xmb\"]/1e3,signal,color=color_opts[\"colors\"][\"observation\"],alpha=0.25,label=None)\n",
    "\n",
    "percentiles = [5,95]\n",
    "post_mean_smb = torch.mean(spatial_samples,axis=0)\n",
    "post_uq_smb = torch.quantile(spatial_samples,percentiles[1]/100,axis=0)\n",
    "post_lq_smb = torch.quantile(spatial_samples,percentiles[0]/100,axis=0)\n",
    "\n",
    "po1, = ax.plot(loader.x[smb_mask]/1e3,post_mean_smb,color=color_opts[\"colors\"][\"posterior\"])\n",
    "po2 = ax.fill_between(loader.x[smb_mask]/1e3,post_lq_smb,post_uq_smb,color=color_opts[\"colors\"][\"posterior\"],alpha=0.2,linewidth=0.0)\n",
    "ax.vlines(loader.x[layer_mask][0]/1e3,ymin=0.05,ymax=0.95,linestyles=\"dashed\",\n",
    "          color=color_opts[\"colors\"][\"boundary_condition\"],\n",
    "          transform=ax.get_xaxis_transform())\n",
    "\n",
    "handles = [(kt1,),(kts,),(po1,po2)]\n",
    "labels = [\"Kottas Mean\",\"Kottas Yearly Data\",\"Posterior\"]\n",
    "\n",
    "ax.spines['bottom'].set_bounds(loader.x[smb_mask][0]/1e3-0.001,loader.x[smb_mask][-1]/1e3+2)\n",
    "ax.set_xlabel(\"Distance from GL [km]\")\n",
    "ax.set_ylabel(\"Surface accumulation [m/a]\")\n",
    "ax.legend(handles=handles,labels=labels,loc = \"best\")\n",
    "\n",
    "fig_name = Path(output_dir,\"paper_figures\",shelf,\"Kottas_data.pdf\")\n",
    "fig_name.parent.mkdir(parents=True,exist_ok=True)\n",
    "fig.savefig(fig_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot comparison of posteriors for all 4 IRHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "posteriors = []\n",
    "observations = []\n",
    "layers = []\n",
    "\n",
    "prior_mismatches = []\n",
    "post_mismatches = []\n",
    "#seeds = [\"layer_0_seed_203\",\"layer_1_seed_201\",\"layer_2_seed_203\",\"layer_3_seed_204\"]\n",
    "#seeds = [\"layer_0_seed_2000\",\"layer_1_seed_2000\",\"layer_2_seed_2000\",\"layer_3_seed_2000\"]\n",
    "#seeds = [\"layer_0_seed_2100\",\"layer_1_seed_2100\",\"layer_2_seed_2100\",\"layer_3_seed_2100\"]\n",
    "# seeds = [\"layer_0_seed_400\",\"layer_1_seed_400\",\"layer_2_seed_400\",\"layer_3_seed_400\"]\n",
    "seeds = [\"layer_0_seed_101\",\"layer_1_seed_100\",\"layer_2_seed_101\",\"layer_3_seed_103\"]\n",
    "# seeds = [\"layer_0_seed_1100\",\"layer_1_seed_1102\",\"layer_2_seed_1104\",\"layer_3_seed_1101\"]\n",
    "for idx,seed in enumerate(seeds):\n",
    "    true_ages = [49.5,  99.5,  149.5, 299.5] #Synthetic_long exp3 gt_v3\n",
    "    fol = Path(output_dir , shelf, exp, \"sbi_sims/post_predictives\" , name,seed)\n",
    "    cfg_path = Path(fol,\"config.yaml\")\n",
    "    cfg = OmegaConf.load(cfg_path)\n",
    "    config_fol = cfg.posterior_config_fol\n",
    "    config_fol = Path(output_dir,shelf,exp,\"sbi_sims/posteriors\",name)\n",
    "    n_post_samples = cfg.n_post_samples\n",
    "    n_predictive_sims = cfg.n_predictive_sims\n",
    "    overwrite = cfg.overwrite_saved_sims\n",
    "    posterior_config = OmegaConf.load(Path(config_fol,str(cfg.name),\"config.yaml\"))\n",
    "    paths = posterior_config.paths\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    output_fol = os.getcwd()\n",
    "    with open(Path(config_fol,str(cfg.name),\"inference.p\"), \"rb\") as f:\n",
    "        if device.type == \"cpu\":\n",
    "            out = posterior_utils.CPU_Unpickler(f).load()\n",
    "        else:\n",
    "            out = pickle.load(f)\n",
    "    inference = out[\"inference\"]\n",
    "    layer_mask = out[\"layer_mask\"]\n",
    "    true_layer = torch.tensor(loader.real_layers[cfg.layer_idx]).float()\n",
    "    posterior = inference.build_posterior(inference._neural_net.to(\"cpu\"))\n",
    "    posterior.set_default_x(true_layer[layer_mask])\n",
    "    posteriors.append(posterior)\n",
    "    observations.append(true_layer)\n",
    "    with open(Path(fol,\"post_predictive.p\"), \"rb\") as f:\n",
    "        out = pickle.load(f)\n",
    "        layer_ages = out[\"ages\"]\n",
    "\n",
    "\n",
    "    nan_mask = ~torch.isnan(true_layer)\n",
    "    layer_entry = {\"layer_x\":loader.x[nan_mask]/1e3,\"layer_depth\":loader.surface[nan_mask] - true_layer[nan_mask].numpy(),\n",
    "                   \"layer_age\":np.median(layer_ages) if shelf == \"Ekstrom\" else true_ages[idx],\"total_thickness\":loader.surface[nan_mask] - loader.base[nan_mask],\n",
    "                   \"LMI_x\":loader.x[layer_mask]/1e3}\n",
    "    layers.append(layer_entry)\n",
    "\n",
    "\n",
    "    with open(Path(fol,\"post_predictive.p\"), \"rb\") as f:\n",
    "        out = pickle.load(f)\n",
    "        bmb_samples = out[\"bmb_samples\"]\n",
    "        best_layers = out[\"best_layers\"]\n",
    "        norms = out[\"norms\"]\n",
    "        ages = out[\"ages\"]\n",
    "        active_trackers = out[\"active_trackers\"]\n",
    "\n",
    "    contour_arrays,norm_arrays,age_arrays,smb_unperturbed_all,smb_cnst_means_all,smb_sds_all,smb_all,bmb_all = loader.load_training_data(layers_fname = posterior_config.layers_fname,mb_fname = posterior_config.mb_fname)\n",
    "    perm = torch.randperm(smb_all.size(0))\n",
    "    perm_idx = perm[:1000]\n",
    "    prior_layers = contour_arrays[idx,perm_idx,:]\n",
    "\n",
    "    prior_mismatch = prior_layers[:,layer_mask].numpy() - true_layer[layer_mask].numpy()\n",
    "    post_mismatch = best_layers - true_layer[layer_mask].numpy()\n",
    "    prior_mismatches.append(prior_mismatch)\n",
    "    post_mismatches.append(post_mismatch)\n",
    "\n",
    "\n",
    "if shelf == \"Ekstrom\":\n",
    "    fig,axs = plotting_utils.compare_posteriors(loader.x[smb_mask]/1e3,posteriors,layers,kottas_smb=kottas_smb)\n",
    "elif shelf == \"Synthetic_long\":\n",
    "    fig,axs = plotting_utils.compare_posteriors(loader.x[smb_mask]/1e3,posteriors,layers,real_smb = true_smb)\n",
    "# fig_name = Path(output_dir,\"paper_figures\",shelf,\"post_comparison.pdf\")\n",
    "# fig_name.parent.mkdir(parents=True,exist_ok=True)\n",
    "# fig.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate RMSE between posteriors and real layer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [5,95]\n",
    "table = [[\"IRH number\",1,2,3,4]]\n",
    "prior_RMSE_mean = [\"prior RMSE average\"]\n",
    "prior_RMSE_uq = [\"prior RMSE {:.0f}% UQ\".format(percentiles[1])]\n",
    "prior_RMSE_lq = [\"prior RMSE {:.0f}% LQ\".format(percentiles[0])]\n",
    "prior_RMSE_sd = [\"prior RMSE SD\"]\n",
    "posterior_RMSE_mean = [\"posterior RMSE average\"]\n",
    "posterior_RMSE_uq = [\"posterior RMSE {:.0f}% UQ\".format(percentiles[1])]\n",
    "posterior_RMSE_lq = [\"posterior RMSE {:.0f}% LQ\".format(percentiles[0])]\n",
    "posterior_RMSE_sd = [\"posterior RMSE SD\"]\n",
    "\n",
    "for i in range(0,len(prior_mismatches)):\n",
    "    print(prior_mismatches[i].shape)\n",
    "    prior_RMSE_mean.append(np.mean(np.sqrt(np.mean(np.square(prior_mismatches[i]),axis=1))))\n",
    "    prior_RMSE_uq.append(np.quantile(np.sqrt(np.mean(np.square(prior_mismatches[i]),axis=1)),percentiles[1]/100))\n",
    "    prior_RMSE_lq.append(np.quantile(np.sqrt(np.mean(np.square(prior_mismatches[i]),axis=1)),percentiles[0]/100))\n",
    "    prior_RMSE_sd.append(np.std(np.sqrt(np.mean(np.square(prior_mismatches[i]),axis=1))))\n",
    "    posterior_RMSE_mean.append(np.mean(np.sqrt(np.mean(np.square(post_mismatches[i]),axis=1))))\n",
    "    posterior_RMSE_uq.append(np.quantile(np.sqrt(np.mean(np.square(post_mismatches[i]),axis=1)),percentiles[1]/100))\n",
    "    posterior_RMSE_lq.append(np.quantile(np.sqrt(np.mean(np.square(post_mismatches[i]),axis=1)),percentiles[0]/100))\n",
    "    posterior_RMSE_sd.append(np.std(np.sqrt(np.mean(np.square(post_mismatches[i]),axis=1))))\n",
    "\n",
    "table.append(prior_RMSE_mean)\n",
    "#table.append(prior_RMSE_uq)\n",
    "#table.append(prior_RMSE_lq)\n",
    "table.append(prior_RMSE_sd)\n",
    "table.append(posterior_RMSE_mean)\n",
    "#table.append(posterior_RMSE_uq)\n",
    "#table.append(posterior_RMSE_lq)\n",
    "table.append(posterior_RMSE_sd)\n",
    "\n",
    "table = list(map(list,zip(*table)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate \n",
    "print(tabulate(table,headers=\"firstrow\"))\n",
    "#output to latex\n",
    "print(tabulate(table,headers=\"firstrow\",tablefmt=\"latex_raw\",floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
